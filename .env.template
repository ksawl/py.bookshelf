PINECONE_API_KEY = "your-pinecone-api-key"
PINECONE_ENV = "us-east-1"  # e.g., "us-west1-gcp"
PINECONE_INDEX = "bookshelf-index"
PINECONE_SERVERLESS_CLOUD = "aws"  # e.g. ['gcp', 'aws', 'azure']
PINECONE_SERVERLESS_REGION = "us-east-1"

CHUNK_TOKENS = "500"
OVERLAP_PCT = "0.2"
BATCH_SIZE = "100"
ENCODING_NAME = "cl100k_base"  # for tiktoken

# choose model: "all-MiniLM-L6-v2" (fast, 384 dim) or "all-mpnet-base-v2" (768 dim)
EMBED_MODEL_NAME = "all-MiniLM-L6-v2"

OLLAMA_API_BASE_URL = "http://localhost:11434"
LLM_MODEL = "llama2"
MAX_CONTEXT_CHARS = "4000"
TOP_K = "5"

DATABASE_URL = "sqlite:///./bookshelf.db"

